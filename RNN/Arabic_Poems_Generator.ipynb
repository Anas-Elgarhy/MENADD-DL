{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Arabic Poems Generator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruqyai/MENADD-DL/blob/main/RNN/Arabic_Poems_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-EWyvS3qUjc"
      },
      "source": [
        "## Arabic Poems Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7-O_D8TqUji"
      },
      "source": [
        "### 1.0 Load the packages\n",
        "<hr/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT1Lant3lG3s"
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uawVxMMSqUjl"
      },
      "source": [
        "Checking the tensorflow version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HGCSz3IOqUjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb9538c-2bbc-4edb-c1a0-ed09c1f584e3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q3n_ZSvqUjj"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers \n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ourZVE1yqUje"
      },
      "source": [
        "### 2.0 Loading the data\n",
        "<hr/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_146r3bjqUje"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Ruqyai/MENADD-DL/main/Data/arabic_poem_generator.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLOTmmGqnPcs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5d4b9c2c-bd63-405e-9b29-dd1dd334c0ed"
      },
      "source": [
        "data = open('arabic_poem_generator.txt', 'rb').read().decode(encoding='utf-8')\n",
        "data[0:300]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'لقينا يوم صهباء سريّه\\nحناظلة لهم في الحرب نيّه\\nلقيناهم بأسياف حداد\\nوأسد لا تفرّ من المنيّه\\nوكان زعيمهم إذ ذاك ليث\\nهزبرا لا يبالي بالرزيّه\\nفخلّفناه وسط القاع ملقى\\nوها أنا طالب قتل البقيّه\\nورحنا بالسيوف نسوق فيهم\\nإلى ربوات معضلة خفيّه\\nوكم من فارس منهم تركنا\\nعليه من صوارمنا قضيّه\\nفوارسنا بنو عبس وإنّا\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzTCJqrMqUjo"
      },
      "source": [
        "### 3.0 Tokenizing the training data\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "KZj8_ZcwqUjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af61acd-5455-45b1-f17e-562019c3a015"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total number of words in corpus:',total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words in corpus: 8212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgXd0QLAqUjs"
      },
      "source": [
        "### 4.0 Preparing the data for training\n",
        "<hr/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Bic7YKtbqUjs"
      },
      "source": [
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2tkadeJqUjv"
      },
      "source": [
        "#### 5.0 Defining the model\n",
        "<hr/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juhW5hyoqg0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18834cff-e655-43ea-cc14-953598e40178"
      },
      "source": [
        "# Defining the model.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150,return_sequences=True)))\n",
        "model.add(Dropout(0.18))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(total_words/2,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 8, 100)            821200    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 8, 300)            301200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8, 300)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4106)              825306    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8212)              33726684  \n",
            "=================================================================\n",
            "Total params: 35,995,190\n",
            "Trainable params: 35,995,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2-J_JWyy75H"
      },
      "source": [
        "#### 6.0 Training the model\n",
        "<hr/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyzrotGNrbPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073473ca-d194-4e41-bf5e-e71ef0cb52d8"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 13043 samples\n",
            "Epoch 1/20\n",
            "13043/13043 [==============================] - 29s 2ms/sample - loss: 8.6852 - accuracy: 0.0256\n",
            "Epoch 2/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 8.1151 - accuracy: 0.0265\n",
            "Epoch 3/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 7.9121 - accuracy: 0.0255\n",
            "Epoch 4/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 7.7547 - accuracy: 0.0269\n",
            "Epoch 5/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 7.5681 - accuracy: 0.0258\n",
            "Epoch 6/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 7.3591 - accuracy: 0.0280\n",
            "Epoch 7/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 7.1398 - accuracy: 0.0318\n",
            "Epoch 8/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 6.9326 - accuracy: 0.0350\n",
            "Epoch 9/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 6.7282 - accuracy: 0.0409\n",
            "Epoch 10/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 6.5243 - accuracy: 0.0498\n",
            "Epoch 11/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 6.3332 - accuracy: 0.0587\n",
            "Epoch 12/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 6.1286 - accuracy: 0.0690\n",
            "Epoch 13/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 5.9261 - accuracy: 0.0808\n",
            "Epoch 14/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 5.7076 - accuracy: 0.0938\n",
            "Epoch 15/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 5.5002 - accuracy: 0.0999\n",
            "Epoch 16/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 5.2804 - accuracy: 0.1130\n",
            "Epoch 17/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 5.0509 - accuracy: 0.1270\n",
            "Epoch 18/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 4.8417 - accuracy: 0.1371\n",
            "Epoch 19/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 4.6414 - accuracy: 0.1507\n",
            "Epoch 20/20\n",
            "13043/13043 [==============================] - 18s 1ms/sample - loss: 4.4355 - accuracy: 0.1701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njl3rjpt1P7x"
      },
      "source": [
        "#### 7.0 Testing the model\n",
        "<hr/>\n",
        "To test the model we have to give 2 inputs:\n",
        "\n",
        "1. Input text or seed text so the network can start predicting. and,\n",
        "2. The number of words you want thenetwork to predict. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3imoT23H1wv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50763b12-24dc-4f72-b8a3-284ae59d4848"
      },
      "source": [
        "seed_text = \"كيف\"\n",
        "next_words =8\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كيف السلوّ عليه تضرّم مدام البرق لقحت كان فخري\n"
          ]
        }
      ]
    }
  ]
}